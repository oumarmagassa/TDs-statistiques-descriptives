{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5ff71e21",
      "metadata": {
        "id": "5ff71e21"
      },
      "source": [
        "# TP : Introduction à PyTorch\n",
        "\n",
        "\n",
        "PyTorch est l'une des bibliothèques de deep learning les plus utilisées aujourd'hui, tant dans la recherche que dans l'industrie. Développé par Meta AI, il se distingue par sa grande flexibilité, sa facilité d'utilisation et son mode d'exécution dynamique, qui permet de construire et d'entraîner des modèles de manière intuitive. C'est un outil incontournable pour expérimenter, prototyper et déployer des réseaux de neurones.\n",
        "\n",
        "Dans ce TP, nous allons découvrir les concepts fondamentaux de PyTorch : la manipulation des tenseurs, l'utilisation de l'autograd pour le calcul automatique de gradients, ainsi que la construction et l'entraînement de modèles simples. L'objectif est de se familiariser avec les briques essentielles permettant de mettre en oeuvre des algorithmes d'apprentissage profond, afin de pouvoir ensuite aborder des architectures plus complexes et des projets plus avancés."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fa32dc6",
      "metadata": {
        "id": "4fa32dc6"
      },
      "source": [
        "#### Import des bilbliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "9e00eac7",
      "metadata": {
        "id": "9e00eac7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71750528",
      "metadata": {
        "id": "71750528"
      },
      "source": [
        "#### Vérification du GPU et configuration du device\n",
        "\n",
        "PyTorch peut utiliser un GPU NVIDIA pour accélérer les calculs.\n",
        "torch.cuda.is_available() permet de vérifier la présence d'une carte GPU compatible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "998180c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "998180c8",
        "outputId": "219a473c-ea0c-4342-ac94-db0341aa7cc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# vérifier l'existance d'une GPU\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# Définir le device qu'on veut utiliser\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73eed3da",
      "metadata": {
        "id": "73eed3da"
      },
      "source": [
        "Q1 : Quel device sera utilisé si aucun GPU n'est disponible ?\n",
        "\n",
        "Réponse : Le CPU sera utilisé. Le code device = \"cuda\" if torch.cuda.is_available() else \"cpu\" retourne \"cpu\" si aucun GPU n'est disponible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e5be53",
      "metadata": {
        "id": "b3e5be53"
      },
      "source": [
        "#### Création de tensors\n",
        "\n",
        "Depuis une liste Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "dd39a30e",
      "metadata": {
        "id": "dd39a30e"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92722652",
      "metadata": {
        "id": "92722652"
      },
      "source": [
        "Depuis un tableau NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a521f1c0",
      "metadata": {
        "id": "a521f1c0"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1557dd74",
      "metadata": {
        "id": "1557dd74"
      },
      "source": [
        "Depuis un autre tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a998a70e",
      "metadata": {
        "id": "a998a70e"
      },
      "outputs": [],
      "source": [
        "x_ones = torch.ones_like(x_data)\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c20380",
      "metadata": {
        "id": "d6c20380"
      },
      "source": [
        "Avec une forme spécifique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3e8beb79",
      "metadata": {
        "id": "3e8beb79"
      },
      "outputs": [],
      "source": [
        "shape = (2,3)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4fa443d",
      "metadata": {
        "id": "a4fa443d"
      },
      "source": [
        "Q1 : Quelle différence entre torch.tensor() et torch.from_numpy() ?\n",
        "    \n",
        "Réponse : torch.tensor() crée toujours une copie des données, tandis que torch.from_numpy() partage la mémoire avec le tableau NumPy d'origine. Modifier le tensor créé avec from_numpy() modifiera aussi le tableau NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "24f4f6f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24f4f6f1",
        "outputId": "a2cf0d71-2525-4358-c2e2-b46f159afcb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7, 7, 7],\n",
            "        [7, 7, 7],\n",
            "        [7, 7, 7]])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Q2 : Crée un tensor 3×3 rempli de 7.\"\"\"\n",
        "tensor_7 = torch.full((3, 3), 7)\n",
        "print(tensor_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb008730",
      "metadata": {
        "id": "cb008730"
      },
      "source": [
        "#### Attributs des tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "25379dc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25379dc6",
        "outputId": "95b20979-fbfd-4b63-a405-1c3fc5f38e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2969, 0.8317, 0.1053, 0.2695, 0.3588, 0.1994],\n",
            "        [0.5472, 0.0062, 0.9516, 0.0753, 0.8860, 0.5832],\n",
            "        [0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
            "        [0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814]])\n",
            "ndim = 2\n",
            "shape = torch.Size([4, 6])\n",
            "dtype = torch.float32\n",
            "device = cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(4,6)\n",
        "print(tensor)\n",
        "\n",
        "print(\"ndim =\", tensor.ndim)      # nombre de dimensions\n",
        "print(\"shape =\", tensor.shape)     # forme du tensor\n",
        "print(\"dtype =\", tensor.dtype)     # type des données\n",
        "print(\"device =\", tensor.device)    # CPU ou GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b320bc",
      "metadata": {
        "id": "c2b320bc"
      },
      "source": [
        "Q1 : Quelle est la dimension d'un tensor de shape (1, 3, 3) ?\n",
        "    \n",
        "Réponse : 3 dimensions (ndim = 3). La première dimension est le batch, les deux suivantes représentent une matrice 3×3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb9b73a",
      "metadata": {
        "id": "2eb9b73a"
      },
      "source": [
        "#### Déplacement vers le GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "3c8469ce",
      "metadata": {
        "id": "3c8469ce"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    tensor_on_gpu = tensor.to('cuda')\n",
        "    tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e75364",
      "metadata": {
        "id": "39e75364"
      },
      "source": [
        "Q1 : Que se passe-t-il si vous essayez tensor_on_gpu.numpy() ?\n",
        "\n",
        "Réponse : Cela génère une erreur car NumPy ne peut pas directement accéder aux tensors sur GPU. Il faut d'abord déplacer le tensor sur CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a497a3",
      "metadata": {
        "id": "f0a497a3"
      },
      "source": [
        "Q2 : Pourquoi faut-il copier le tensor sur le CPU avant d'appeler .numpy() ?\n",
        "    \n",
        "Réponse : Parce que NumPy ne supporte que les données en mémoire CPU. Les tensors GPU sont stockés dans la mémoire de la carte graphique, inaccessible directement par NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf90a4a",
      "metadata": {
        "id": "4bf90a4a"
      },
      "source": [
        "#### Indexation et slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "fdec090f",
      "metadata": {
        "id": "fdec090f"
      },
      "outputs": [],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[0]       # première ligne\n",
        "tensor[:, 0]    # première colonne\n",
        "tensor[..., -1] # dernière colonne\n",
        "\n",
        "tensor[:, 1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "7a492c06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a492c06",
        "outputId": "cb42a3f5-f0a6-497b-8181-1c0c3d728e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [9., 9., 9., 9.]])\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Q1 : Modifie la dernière ligne pour qu'elle contienne [9, 9, 9, 9]. \"\"\"\n",
        "\n",
        "tensor[-1] = 9\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a951ff5d",
      "metadata": {
        "id": "a951ff5d"
      },
      "source": [
        "#### Concaténation de tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "e60f931d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e60f931d",
        "outputId": "aa51fcfa-9c18-471a-fcb4-494babfd4f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d16b12",
      "metadata": {
        "id": "b1d16b12"
      },
      "source": [
        "Q1 : Si tensor est un tensor de size (4,4), quelle sera la taille de t1 ?\n",
        "    \n",
        "Réponse : (4, 12). La concaténation se fait sur dim=1 (colonnes), donc on obtient 4 lignes et 4+4+4=12 colonnes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40da469",
      "metadata": {
        "id": "d40da469"
      },
      "source": [
        "#### Opérations mathématiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85dbcad2",
      "metadata": {
        "id": "85dbcad2"
      },
      "source": [
        "Multiplication matricielle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "0dc15d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc15d6f",
        "outputId": "be7b6ecf-6f34-4b43-9e90-875a790f1cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  3.,   3.,   3.,  27.],\n",
            "        [  3.,   3.,   3.,  27.],\n",
            "        [  3.,   3.,   3.,  27.],\n",
            "        [ 27.,  27.,  27., 324.]])\n"
          ]
        }
      ],
      "source": [
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "y3 = torch.matmul(tensor, tensor.T)\n",
        "print(y3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f75809c4",
      "metadata": {
        "id": "f75809c4"
      },
      "source": [
        "Produit élément par élément"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "55d9a6ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55d9a6ea",
        "outputId": "65ca11d7-467f-47c9-cb8a-d30c55e6952b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [81., 81., 81., 81.]])\n"
          ]
        }
      ],
      "source": [
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "z3 =torch.mul(tensor, tensor)\n",
        "print(z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c712d01",
      "metadata": {
        "id": "6c712d01"
      },
      "source": [
        "Q1 : Quelle est la condition pour que deux matrices puissent être multipliées ?\n",
        "    \n",
        "Réponse :  Le nombre de colonnes de la première matrice doit être égal au nombre de lignes de la seconde. Pour A(m×n) @ B(p×q), il faut n = p, et le résultat sera de taille (m×q)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecafe92d",
      "metadata": {
        "id": "ecafe92d"
      },
      "source": [
        "Opérations in-place\n",
        "\n",
        "Ces opérations modifient directement le tensor d’origine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2ff8f5f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff8f5f5",
        "outputId": "9bfe182b-e249-4e84-e850-e9e9b09f9390"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  5.,  6.,  6.],\n",
              "        [ 6.,  5.,  6.,  6.],\n",
              "        [ 6.,  5.,  6.,  6.],\n",
              "        [14., 14., 14., 14.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "tensor.add_(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daeaf646",
      "metadata": {
        "id": "daeaf646"
      },
      "source": [
        "Q2 : Pourquoi faut-il faire attention en apprentissage automatique lorsqu'on utilise des opérations in-place ?\n",
        "    \n",
        "Réponse : Les opérations in-place peuvent perturber le calcul des gradients (autograd) car elles modifient les valeurs originales nécessaires à la rétropropagation. Elles peuvent causer des erreurs dans le graphe de calcul."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021abd5b",
      "metadata": {
        "id": "021abd5b"
      },
      "source": [
        "#### Conversion entre NumPy et PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b66426eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66426eb",
        "outputId": "5abfd18f-abe5-4ef3-9b75-1ee19cc6fd23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "n = t.numpy()\n",
        "t.add_(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfddb715",
      "metadata": {
        "id": "dfddb715"
      },
      "source": [
        "Q3 : Que se passe-t-il si l'on modifie n après la conversion ?\n",
        "    \n",
        "Réponse:  Le tensor t sera également modifié car ils partagent la même mémoire. C'est une caractéristique de .numpy() qui crée une vue, pas une copie."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2bca211",
      "metadata": {
        "id": "c2bca211"
      },
      "source": [
        "#### Manipulation des formes (reshape, view, squeeze…)\n",
        "\n",
        "Reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "eb164283",
      "metadata": {
        "id": "eb164283"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(1., 8.)\n",
        "x_reshaped = x.reshape(1,1,7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d9d4a6",
      "metadata": {
        "id": "93d9d4a6"
      },
      "source": [
        "View (partage la mémoire)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "f01e702e",
      "metadata": {
        "id": "f01e702e"
      },
      "outputs": [],
      "source": [
        "z = x.view(1, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "944101a8",
      "metadata": {
        "id": "944101a8"
      },
      "source": [
        "Squeeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "523bccc6",
      "metadata": {
        "id": "523bccc6"
      },
      "outputs": [],
      "source": [
        "x_squeezed = x_reshaped.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "232e7674",
      "metadata": {
        "id": "232e7674"
      },
      "source": [
        "Permute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "b8076873",
      "metadata": {
        "id": "b8076873"
      },
      "outputs": [],
      "source": [
        "x_permuted = x_reshaped .permute(2, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c680f68b",
      "metadata": {
        "id": "c680f68b"
      },
      "source": [
        "Q1 : Quelle est la différence entre .view() et .reshape() ?\n",
        "    \n",
        "Réponse : .view() nécessite que le tensor soit contigu en mémoire et retourne une vue (partage la mémoire). .reshape() peut fonctionner sur des tensors non contigus et peut créer une copie si nécessaire. .reshape() est plus flexible mais .view() est plus rapide quand applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb943493",
      "metadata": {
        "id": "fb943493"
      },
      "source": [
        "#### Indexation avancée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "28a5961f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28a5961f",
        "outputId": "8a3de5f2-1f94-4938-bae9-1dc4815a1f0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x[:, 0]      # ligne 0 de la dimension 1\n",
        "x[:, 1, 1]   # élément central\n",
        "x[0, 0, :]   # première ligne du premier batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "adafa46d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adafa46d",
        "outputId": "0740e50f-7b6e-45af-e590-19e8c83083db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 9])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Q1 : Extraire la diagonale [1, 5, 9]\"\"\"\n",
        "\n",
        "diagonal = torch.diagonal(x[0])\n",
        "print(diagonal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d97f82f",
      "metadata": {
        "id": "2d97f82f"
      },
      "source": [
        "#### Graine aléatoire (random seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "034300c4",
      "metadata": {
        "id": "034300c4"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "random_tensor_C = torch.rand(3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4cfb59",
      "metadata": {
        "id": "be4cfb59"
      },
      "source": [
        "Q1 : À quoi sert le random seed ?\n",
        "    \n",
        "Réponse : Il permet de rendre les résultats reproductibles. En fixant la graine, on obtient toujours la même séquence de nombres \"aléatoires\", ce qui est essentiel pour déboguer et comparer des expériences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad59a42a",
      "metadata": {
        "id": "ad59a42a"
      },
      "source": [
        "#### Calcul de gradients et Autograd\n",
        "\n",
        "PyTorch possède un système automatique de différentiation appelé Autograd.\n",
        "Il permet de calculer facilement les gradients, indispensables pour l'apprentissage automatique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e0aaba",
      "metadata": {
        "id": "43e0aaba"
      },
      "source": [
        "##### Activer le suivi des gradients : requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "559b3290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "559b3290",
        "outputId": "f0c1f035-d7a1-4fe8-8e50-9d2fec423a79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x**2 + 3*x + 1\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc807a3d",
      "metadata": {
        "id": "fc807a3d"
      },
      "source": [
        "##### Calcul du gradient avec .backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "e0f36fb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f36fb5",
        "outputId": "0cc6527d-e086-4342-f4ed-8baada11422e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b47a2d",
      "metadata": {
        "id": "f0b47a2d"
      },
      "source": [
        "\"x.grad\" contient la dérivée de y par rapport à x qui est égale à 2*x+3\n",
        "\n",
        "Pour x=2, on devrait obtenir 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "b291076a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b291076a",
        "outputId": "1065607b-f09d-4df4-fd94-d7c18d0289d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(15.)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Q1 : Trouver le gradient de la fonction z = 5*(x**3) pour x = 1.0\"\"\"\n",
        "\n",
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "z = 5 * (x**3)\n",
        "z.backward()\n",
        "print(x.grad)  # Devrait afficher 15.0 (dérivée = 15*x^2, donc 15*1 = 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9396d877",
      "metadata": {
        "id": "9396d877"
      },
      "source": [
        "##### Désactiver le suivi des gradients : with torch.no_grad()\n",
        "\n",
        "Certaines opérations ne doivent pas suivre le calcul des gradients\n",
        "(ex : évaluation d’un modèle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "eeff6ce8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeff6ce8",
        "outputId": "dd88e710-6449-4c40-caf5-b00ee965aa4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x * 3\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = y * 5\n",
        "\n",
        "print(z.requires_grad)  # False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64dc0438",
      "metadata": {
        "id": "64dc0438"
      },
      "source": [
        "Q1 : Pourquoi ne pas calculer les gradients durant la phase de test d’un modèle ?\n",
        "\n",
        "Réponse : Pour économiser de la mémoire et accélérer les calculs. Durant l'inférence, on n'a pas besoin de calculer les gradients puisqu'on ne met pas à jour les poids. torch.no_grad() évite de construire le graphe de calcul."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3fe903",
      "metadata": {
        "id": "af3fe903"
      },
      "source": [
        "##### Retirer un tensor du graphe de calcul : .detach()\n",
        "\n",
        "detach() crée une copie du tensor sans suivi des gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "c376b0b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c376b0b6",
        "outputId": "889b1cbb-f414-4418-b9d3-690d97883f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x * 4\n",
        "\n",
        "z = y.detach()\n",
        "print(z.requires_grad)  # False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f306128e",
      "metadata": {
        "id": "f306128e"
      },
      "source": [
        "Q1 : Quelle différence entre detach() et with torch.no_grad() ?\n",
        "    \n",
        "Réponse : .detach() crée un nouveau tensor détaché du graphe de calcul, mais seulement pour ce tensor spécifique. with torch.no_grad(): désactive le suivi des gradients pour toutes les opérations dans son contexte. .detach() est pour un tensor, no_grad() est pour un bloc de code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9db0e6e6",
      "metadata": {
        "id": "9db0e6e6"
      },
      "source": [
        "##### Exemple complet : descente de gradient simple\n",
        "\n",
        "On veut minimiser la fonction : f(w) = (w−4)²\n",
        "\n",
        "Étape 1 : Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "72d4585d",
      "metadata": {
        "id": "72d4585d"
      },
      "outputs": [],
      "source": [
        "w = torch.tensor(0.0, requires_grad=True)\n",
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce94dd0",
      "metadata": {
        "id": "6ce94dd0"
      },
      "source": [
        "Étape 2 : Boucle d’optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "45891679",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45891679",
        "outputId": "d7c1d89d-e850-4997-9b85-688c62b7dddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 | w = 2.7110 | loss = 12.0069\n",
            "Iteration 2 | w = 2.7368 | loss = 1.6615\n",
            "Iteration 3 | w = 2.7620 | loss = 1.5957\n",
            "Iteration 4 | w = 2.7868 | loss = 1.5326\n",
            "Iteration 5 | w = 2.8111 | loss = 1.4719\n",
            "Iteration 6 | w = 2.8348 | loss = 1.4136\n",
            "Iteration 7 | w = 2.8581 | loss = 1.3576\n",
            "Iteration 8 | w = 2.8810 | loss = 1.3038\n",
            "Iteration 9 | w = 2.9034 | loss = 1.2522\n",
            "Iteration 10 | w = 2.9253 | loss = 1.2026\n",
            "Iteration 11 | w = 2.9468 | loss = 1.1550\n",
            "Iteration 12 | w = 2.9679 | loss = 1.1093\n",
            "Iteration 13 | w = 2.9885 | loss = 1.0653\n",
            "Iteration 14 | w = 3.0087 | loss = 1.0231\n",
            "Iteration 15 | w = 3.0286 | loss = 0.9826\n",
            "Iteration 16 | w = 3.0480 | loss = 0.9437\n",
            "Iteration 17 | w = 3.0670 | loss = 0.9063\n",
            "Iteration 18 | w = 3.0857 | loss = 0.8705\n",
            "Iteration 19 | w = 3.1040 | loss = 0.8360\n",
            "Iteration 20 | w = 3.1219 | loss = 0.8029\n"
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "    loss = (w - 4)**2\n",
        "\n",
        "    loss.backward()        # calcul du gradient\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad  # mise à jour\n",
        "\n",
        "    w.grad.zero_()         # remettre le gradient à zéro !\n",
        "\n",
        "    print(f\"Iteration {i+1} | w = {w.item():.4f} | loss = {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23309c19",
      "metadata": {
        "id": "23309c19"
      },
      "source": [
        "Q1 : Que se passe-t-il si tu ne fais pas w.grad.zero_() ?\n",
        "    \n",
        "Réponse : Les gradients s'accumulent à chaque itération. Le nouveau gradient s'ajoute à l'ancien au lieu de le remplacer, ce qui fausse complètement l'optimisation et empêche la convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2af520a6",
      "metadata": {
        "id": "2af520a6"
      },
      "source": [
        "##### model.eval() : à quoi ça sert ?\n",
        "\n",
        "model.eval() place le modèle en mode évaluation.\n",
        "\n",
        "Cela affecte uniquement certains modules qui se comportent différemment entre :\n",
        "\n",
        "    mode entraînement : model.train()\n",
        "    mode évaluation : model.eval()\n",
        "\n",
        "model.eval() permet de modifier le comportement :\n",
        "\n",
        "BatchNorm\n",
        "\n",
        "    Entrainement : utilise les statistiques du batch courant\n",
        "    Évaluation : utilise les moyennes/variances stockées pendant l'apprentissage\n",
        "\n",
        "Dropout\n",
        "\n",
        "    Entrainement : désactive aléatoirement certains neurones\n",
        "    Évaluation : aucun dropout (les neurones restent actifs à 100 %)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c731e790",
      "metadata": {
        "id": "c731e790"
      },
      "source": [
        "#### Régression linéaire avec PyTorch (sans nn.Module)\n",
        "\n",
        "Dans cette section, on va entraîner un modèle simple : y = 3*x + 2\n",
        "\n",
        "L'objectif est que de retrouve automatiquement les paramètres w et b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "68f33b9c",
      "metadata": {
        "id": "68f33b9c"
      },
      "outputs": [],
      "source": [
        "# Données d'entraînement\n",
        "\n",
        "X = torch.arange(0, 10, dtype=torch.float32).reshape(-1, 1)\n",
        "y = 3 * X + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "76c8fc9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76c8fc9a",
        "outputId": "03b8550d-3127-4083-c9cd-d6d27c401c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1103], requires_grad=True) tensor([-1.6898], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Initialisation des paramètres du modèle (w et b)\n",
        "\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True )\n",
        "print(w, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "bfd0ebe1",
      "metadata": {
        "id": "bfd0ebe1"
      },
      "outputs": [],
      "source": [
        "# Définition du modèle\n",
        "\n",
        "def linear_model(x):\n",
        "    return w * x + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "7f26d9ca",
      "metadata": {
        "id": "7f26d9ca"
      },
      "outputs": [],
      "source": [
        "# Fonction de perte (MSE)\n",
        "\n",
        "def loss_fn(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "3659274b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3659274b",
        "outputId": "3803a69b-7a0a-46e4-bd97-7b30d635a8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss = 178.1420 | w=2.520, b=-1.446\n",
            "Epoch 20 | Loss = 2.5207 | w=3.468, b=-0.934\n",
            "Epoch 40 | Loss = 2.0097 | w=3.418, b=-0.620\n",
            "Epoch 60 | Loss = 1.6023 | w=3.373, b=-0.339\n",
            "Epoch 80 | Loss = 1.2775 | w=3.333, b=-0.089\n",
            "Epoch 100 | Loss = 1.0186 | w=3.297, b=0.135\n",
            "Epoch 120 | Loss = 0.8121 | w=3.266, b=0.335\n",
            "Epoch 140 | Loss = 0.6475 | w=3.237, b=0.513\n",
            "Epoch 160 | Loss = 0.5162 | w=3.212, b=0.672\n",
            "Epoch 180 | Loss = 0.4116 | w=3.189, b=0.814\n"
          ]
        }
      ],
      "source": [
        "# Boucle d’entraînement\n",
        "\n",
        "learning_rate = 0.01\n",
        "for epoch in range(200):\n",
        "    y_pred = linear_model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss = {loss:.4f} | w={w.item():.3f}, b={b.item():.3f}\")\n",
        "\n",
        "# À la fin, w devrait être proche de 3 et b proche de 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "360cee30",
      "metadata": {
        "id": "360cee30"
      },
      "source": [
        "Q1 : Que se passe-t-il si on augmente le learning_rate à 1.0 ?\n",
        "    \n",
        "Réponse : Le modèle risque de diverger. Un taux d'apprentissage trop élevé fait des mises à jour trop importantes, dépassant le minimum et causant des oscillations ou une explosion de la perte."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a77137",
      "metadata": {
        "id": "85a77137"
      },
      "source": [
        "#### Régression linéaire avec torch.nn\n",
        "\n",
        "Définition du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "9d57912c",
      "metadata": {
        "id": "9d57912c"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features=1, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c150d7a",
      "metadata": {
        "id": "8c150d7a"
      },
      "source": [
        "Fonction de perte + Optimiseur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "e8f17b5f",
      "metadata": {
        "id": "e8f17b5f"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2c4d2e",
      "metadata": {
        "id": "3e2c4d2e"
      },
      "source": [
        "Boucle d’entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "e8526610",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8526610",
        "outputId": "53f58d40-5ce0-4d6b-db67-db8783996209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss = 327.6701\n",
            "Epoch 20 | Loss = 1.3990\n",
            "Epoch 40 | Loss = 1.1154\n",
            "Epoch 60 | Loss = 0.8893\n",
            "Epoch 80 | Loss = 0.7090\n",
            "Epoch 100 | Loss = 0.5653\n",
            "Epoch 120 | Loss = 0.4507\n",
            "Epoch 140 | Loss = 0.3593\n",
            "Epoch 160 | Loss = 0.2865\n",
            "Epoch 180 | Loss = 0.2284\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(200):\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss = {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "44a3dff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a3dff3",
        "outputId": "cf59b584-7075-447c-bed6-3cc804122373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight: tensor([[3.1265]])\n",
            "linear.bias: tensor([1.2069])\n",
            "tensor([[3.1265]])\n",
            "tensor([1.2069])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Q1 : Comment accéder aux paramètres appris ?\"\"\"\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.data}\")\n",
        "# ou\n",
        "print(model.linear.weight.data)\n",
        "print(model.linear.bias.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "fa299edf",
      "metadata": {
        "id": "fa299edf"
      },
      "outputs": [],
      "source": [
        "\"\"\"Q2 : Ajouter une deuxième couche linéaire.\"\"\"\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_features=1, out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=10, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b178e65",
      "metadata": {
        "id": "1b178e65"
      },
      "source": [
        "#### Qu'est-ce que ça change d'ajouter une deuxième couche linéaire ?\n",
        "\n",
        "Dans PyTorch, une couche linéaire réalise la transformation suivante :\n",
        "\n",
        "$$\\text{Linear}(x) = Wx + b$$\n",
        "\n",
        "---\n",
        "\n",
        "##### 1. Une seule couche linéaire\n",
        "\n",
        "Si notre modèle contient une seule couche linéaire, alors il apprend une relation strictement linéaire :\n",
        "\n",
        "$$\\hat{y} = W_1 x + b_1$$\n",
        "\n",
        "C'est équivalent à une régression linéaire classique. Le modèle ne peut apprendre qu'une droite.\n",
        "\n",
        "---\n",
        "\n",
        "##### 2. Deux couches linéaires consécutives (sans activation)\n",
        "\n",
        "Exemple :\n",
        "\n",
        "```python\n",
        "self.linear1 = nn.Linear(1, 1)\n",
        "self.linear2 = nn.Linear(1, 1)\n",
        "\n",
        "def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n",
        "```\n",
        "Mathématiquement :\n",
        "\n",
        "$$\\hat{y} = W_2 (W_1 x + b_1) + b_2$$\n",
        "    \n",
        "En développant :\n",
        "\n",
        "$$\\hat{y} =  (W_1 W_2) x + (W_2 b_1 + b_2)$$\n",
        "\n",
        "Le modèle reste linéaire... Même si on ajoute plusieurs couches linéaires consécutives, sans activation, le résultat final est toujours une seule transformation linéaire équivalente.\n",
        "\n",
        "##### Quand est-ce que plusieurs couches deviennent intéressantes ?\n",
        "\n",
        "Uniquement quand on ajoute une fonction d'activation non linéaire entre les couches :\n",
        "\n",
        "```python\n",
        "self.linear1 = nn.Linear(1, 10)\n",
        "self.relu = nn.ReLU()\n",
        "self.linear2 = nn.Linear(10, 1)\n",
        "\n",
        "def forward(self, x):\n",
        "    return self.linear2(self.relu(self.linear1(x)))\n",
        "```\n",
        "\n",
        "Maintenant notre modèle devient :\n",
        "\n",
        "$$\\hat{y} = W_2 \\sigma(W_1 x + b_1) + b_2$$\n",
        "\n",
        "où $\\sigma$ est une non-linéarité (ReLU, tanh, sigmoid…).\n",
        "\n",
        "Le modèle n'est plus linéaire. Il peut apprendre des relations non linéaires, comme : courbes, polynômes, fonctions périodiques, données complexes…"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1565d522",
      "metadata": {
        "id": "1565d522"
      },
      "source": [
        "#### Dataset & DataLoader (gestion des données)\n",
        "\n",
        "Les DataLoader permettent de charger les données par batches, mélangées (shuffle) ou non.\n",
        "\n",
        "Création d’un Dataset personnalisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "1a0544b6",
      "metadata": {
        "id": "1a0544b6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.X = torch.arange(0, 10, dtype=torch.float32).reshape(-1, 1)\n",
        "        self.y = 3 * self.X + 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e9217b",
      "metadata": {
        "id": "c0e9217b"
      },
      "source": [
        "Charger le Dataset dans un DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "ec07d888",
      "metadata": {
        "id": "ec07d888"
      },
      "outputs": [],
      "source": [
        "dataset = SimpleDataset()\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830ac82e",
      "metadata": {
        "id": "830ac82e"
      },
      "source": [
        "Parcourir un DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "db29832c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db29832c",
        "outputId": "c63f7e96-18e3-434a-ee35-8debf91fefa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [9.]]) tensor([[ 2.],\n",
            "        [29.]])\n",
            "tensor([[3.],\n",
            "        [7.]]) tensor([[11.],\n",
            "        [23.]])\n",
            "tensor([[2.],\n",
            "        [5.]]) tensor([[ 8.],\n",
            "        [17.]])\n",
            "tensor([[6.],\n",
            "        [1.]]) tensor([[20.],\n",
            "        [ 5.]])\n",
            "tensor([[8.],\n",
            "        [4.]]) tensor([[26.],\n",
            "        [14.]])\n"
          ]
        }
      ],
      "source": [
        "for batch_X, batch_y in loader:\n",
        "    print(batch_X, batch_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364f7229",
      "metadata": {
        "id": "364f7229"
      },
      "source": [
        "Q1 : Que fait l'argument shuffle=True ?\n",
        "    \n",
        "Réponse : Il mélange aléatoirement l'ordre des échantillons à chaque epoch. Cela aide à éviter que le modèle apprenne l'ordre des données et améliore la généralisation en introduisant plus de variabilité dans les batches."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41969e83",
      "metadata": {
        "id": "41969e83"
      },
      "source": [
        "#### Application sur un vrai jeu de données d'images (MNIST via torchvision)\n",
        "\n",
        "MNIST contient des images de chiffres 28×28 = 784 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "c43fdad8",
      "metadata": {
        "id": "c43fdad8"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3700563",
      "metadata": {
        "id": "e3700563"
      },
      "source": [
        "Fonction pour convertir les images en tenseurs et les normaliser (optionnel mais classique)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "246b78eb",
      "metadata": {
        "id": "246b78eb"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),              # image PIL to tensor (C,H,W) entre 0 et 1\n",
        "    # transforms.Normalize((0.5,), (0.5,))  # optionnel : normalisation\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d45482e",
      "metadata": {
        "id": "3d45482e"
      },
      "source": [
        "Télécharger MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "d9400bb3",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9400bb3",
        "outputId": "78dc9be4-8a5f-48cd-ba51-930fd8016953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.88MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 155kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.72MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Le dataset sera téléchargé dans le dossier \"./data\"\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "bafb6868",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "bafb6868",
        "outputId": "8f88c1bd-a8e0-42ae-d41f-1edcd61a2f43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df73e9b",
      "metadata": {
        "id": "4df73e9b"
      },
      "source": [
        "Créer les Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "52ec0bea",
      "metadata": {
        "id": "52ec0bea"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a304de",
      "metadata": {
        "id": "83a304de"
      },
      "source": [
        "### Réseaux de Neurones Profonds : MLP & CNN\n",
        "\n",
        "Dans cette partie, nous allons créer :\n",
        "\n",
        "    un MLP (Multi-Layer Perceptron) pour la classification de chiffres (MNIST)\n",
        "\n",
        "    un CNN simple pour apprendre à classifier des images 1 canal (MNIST)\n",
        "\n",
        "L'objectif est d'introduire les principales briques des architectures modernes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7159f1c",
      "metadata": {
        "id": "f7159f1c"
      },
      "source": [
        "#### MLP (Multi-Layer Perceptron)\n",
        "\n",
        "Un MLP est composé uniquement de couches linéaires, séparées par des activations.\n",
        "\n",
        "Ex :\n",
        "Entrée -> Linear -> ReLU -> Linear -> ReLU -> Linear -> Sortie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "2b934141",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b934141",
        "outputId": "71bd2a6f-ffbb-44d7-fc9c-1b33dea1462c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Modèle MLP TODO \"\"\"\n",
        "\"\"\"Modèle MLP\"\"\"\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Architecture : 784 -> 128 -> 64 -> 10\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Flatten(),                # Aplatir l'image 28x28 en vecteur de 784\n",
        "            nn.Linear(28*28, 128),       # Première couche cachée\n",
        "            nn.ReLU(),                   # Activation\n",
        "            nn.Linear(128, 64),          # Deuxième couche cachée\n",
        "            nn.ReLU(),                   # Activation\n",
        "            nn.Linear(64, 10)            # Couche de sortie (10 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "mlp = MLP()\n",
        "print(mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "662e7f1d",
      "metadata": {
        "id": "662e7f1d"
      },
      "source": [
        "Fonction de perte + Optimiseur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "04927ae9",
      "metadata": {
        "id": "04927ae9"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd5332e",
      "metadata": {
        "id": "ebd5332e"
      },
      "source": [
        "Exemple de la boucle d'entraînement (un seul epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "832f9ba5",
      "metadata": {
        "id": "832f9ba5"
      },
      "outputs": [],
      "source": [
        "for X_batch, y_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = mlp(X_batch)\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d688b9af",
      "metadata": {
        "id": "d688b9af"
      },
      "source": [
        "Q1 : Quelle activation remplace ReLU dans un MLP profond ?\n",
        "    \n",
        "Réponse :  Plusieurs alternatives existent : Leaky ReLU (évite les neurones morts), ELU, GELU (utilisé dans les Transformers), Swish/SiLU, ou Mish. Ces activations ont souvent de meilleures propriétés de gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05665381",
      "metadata": {
        "id": "05665381"
      },
      "source": [
        "Exemple de code d'entrainement du modèle pour plusieurs epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "034e30b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "034e30b6",
        "outputId": "23801ea6-cf4f-442f-f04b-99ed436d1b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | Loss: 0.1421\n",
            "Epoch [2/10] | Loss: 0.0966\n",
            "Epoch [3/10] | Loss: 0.0736\n",
            "Epoch [4/10] | Loss: 0.0557\n",
            "Epoch [5/10] | Loss: 0.0458\n",
            "Epoch [6/10] | Loss: 0.0378\n",
            "Epoch [7/10] | Loss: 0.0311\n",
            "Epoch [8/10] | Loss: 0.0249\n",
            "Epoch [9/10] | Loss: 0.0214\n",
            "Epoch [10/10] | Loss: 0.0187\n",
            "Entraînement terminé!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Boucle d'entrainement pour 10 epochs\"\"\"\n",
        "\n",
        "epochs = 10\n",
        "plt_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    mlp.train()  # Mode entraînement\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Remettre les gradients à zéro\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = mlp(X_batch)\n",
        "\n",
        "        # Calcul de la loss\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Mise à jour des poids\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumuler la loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Loss moyenne pour l'epoch\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    plt_loss.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Entraînement terminé!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "705695af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "705695af",
        "outputId": "b5c86603-6b36-449e-de89-53629dbab25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a0f00aa9a00>]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(plt_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ab2de5",
      "metadata": {
        "id": "52ab2de5"
      },
      "source": [
        "Evaluation sur le jeu de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "40ee99ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40ee99ec",
        "outputId": "8b1e060a-2d0b-418b-a8d8-ec7f044d3037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy : 97.990%\n"
          ]
        }
      ],
      "source": [
        "mlp.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        # Forward pass\n",
        "        y_pred = mlp(X_batch)\n",
        "\n",
        "        # Prédictions\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "\n",
        "        # Compter les bonnes prédictions\n",
        "        test_total += y_batch.size(0)\n",
        "        test_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "test_acc = 100 * test_correct / test_total\n",
        "print(f\"Final Test Accuracy : {test_acc:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971106b1",
      "metadata": {
        "id": "971106b1"
      },
      "source": [
        "#### Notes:\n",
        "\n",
        "- model.train() :\n",
        "    active certaines couches comme Dropout, BatchNorm en mode entraînement.\n",
        "\n",
        "- model.eval() :\n",
        "    met le modèle en mode évaluation (pas de Dropout, BatchNorm en mode inference).\n",
        "\n",
        "- with torch.no_grad() :\n",
        "    désactive la construction du graphe de gradients (moins de mémoire, plus rapide).\n",
        "\n",
        "- torch.max(y_pred, dim=1) :\n",
        "    récupère la classe prédite."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2cb8cf",
      "metadata": {
        "id": "6e2cb8cf"
      },
      "source": [
        "#### NN (Convolutional Neural Network)\n",
        "\n",
        "Les CNN sont utilisés pour traiter les images.\n",
        "Ils exploitent :\n",
        "\n",
        "    des filtres convolutifs\n",
        "\n",
        "    des features locales\n",
        "\n",
        "    des réductions de dimension (MaxPool)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44a2e40",
      "metadata": {
        "id": "e44a2e40"
      },
      "source": [
        "Architecture d'un CNN simple\n",
        "Schéma général :\n",
        "\n",
        "- Entrée (1×28×28)\n",
        "- Conv2d\n",
        "- ReLU\n",
        "- MaxPool2d\n",
        "- Flatten\n",
        "- Linear\n",
        "- Linear\n",
        "- Sortie (10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "6139c2de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6139c2de",
        "outputId": "2462636d-4d87-4be2-95af-e7d86c2de1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Linear(in_features=1568, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),  # 28x28 -> 28x28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),  # 14x14 -> 14x14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 14x14 -> 7x7\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 7 * 7, 128),  # 32 canaux * 7 * 7 = 1568\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)  # 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        return self.fc_layers(x)\n",
        "\n",
        "cnn = SimpleCNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "4e693b8a",
      "metadata": {
        "id": "4e693b8a"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "12c9c0ab",
      "metadata": {
        "id": "12c9c0ab"
      },
      "outputs": [],
      "source": [
        "for X_batch, y_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = cnn(X_batch)\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e94dbea7",
      "metadata": {
        "id": "e94dbea7"
      },
      "source": [
        "Q1 : Quel est le rôle de MaxPool2d ?\n",
        "    \n",
        "Réponse : Réduire la dimension spatiale (downsampling) en gardant la valeur maximale dans chaque région. Cela réduit le nombre de paramètres, diminue le surapprentissage, crée une invariance à de petites translations, et extrait les features les plus saillantes.\n",
        "    \n",
        "Q2 : Pourquoi les CNN sont-ils plus efficaces que les MLP sur les images ?\n",
        "\n",
        "Réponse : Les CNN exploitent la structure spatiale des images grâce à :\n",
        "\n",
        "- Localité : les filtres convolutifs détectent des patterns locaux\n",
        "- Partage de paramètres : les mêmes filtres sont appliqués partout (beaucoup moins de paramètres)\n",
        "- Invariance par translation : un pattern est reconnu quelle que soit sa position\n",
        "- Hiérarchie de features : des edges simples aux objets complexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "5d0df888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0df888",
        "outputId": "fdc1c030-d5a0-4ff2-ae1d-5859284f4c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdvancedCNN(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=1152, out_features=256, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Input shape: torch.Size([1, 1, 28, 28])\n",
            "Output shape: torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Créer un CNN avec :\n",
        "    3 couches convolutives\n",
        "    1 couche dense finale\n",
        "    des BatchNorm entre les convolutions\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Créer un CNN avec :\n",
        "    3 couches convolutives\n",
        "    1 couche dense finale\n",
        "    des BatchNorm entre les convolutions\n",
        "\"\"\"\n",
        "\n",
        "class AdvancedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # Première couche convolutive\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # 1x28x28 -> 32x28x28\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 32x28x28 -> 32x14x14\n",
        "\n",
        "            # Deuxième couche convolutive\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # 32x14x14 -> 64x14x14\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 64x14x14 -> 64x7x7\n",
        "\n",
        "            # Troisième couche convolutive\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 64x7x7 -> 128x7x7\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 128x7x7 -> 128x3x3\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 3 * 3, 256),  # 128 * 3 * 3 = 1152\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 10)  # 10 classes de sortie\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        return self.fc_layers(x)\n",
        "\n",
        "cnn_advanced = AdvancedCNN()\n",
        "print(cnn_advanced)\n",
        "\n",
        "# Vérifier les dimensions\n",
        "test_input = torch.randn(1, 1, 28, 28)\n",
        "output = cnn_advanced(test_input)\n",
        "print(f\"\\nInput shape: {test_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82ed991",
      "metadata": {
        "id": "a82ed991"
      },
      "source": [
        "### Exercice : Construire un Autoencodeur\n",
        "\n",
        "Un autoencodeur est un réseau capable de :\n",
        "\n",
        "- Encoder une donnée (image) dans un espace latent de dimension réduite.\n",
        "- Décoder cette représentation latente pour reconstruire l'image d'origine.\n",
        "\n",
        "Utilisation : débruitage, compression, détection d'anomalies, génération…\n",
        "\n",
        "\n",
        "Consignes :\n",
        "\n",
        "1. Créer une classe Autoencoder(nn.Module)\n",
        "\n",
        "2. Implémenter :\n",
        "    - un encodeur (MLP)\n",
        "    - un espace latent de faible dimension (ex : 16)\n",
        "    - un decodeur symétrique\n",
        "\n",
        "\n",
        "3. Utiliser une loss MSE pour mesurer la qualité de reconstruction\n",
        "\n",
        "4. Entraîner l'autoencodeur sur MNIST (train set uniquement)\n",
        "\n",
        "5. Afficher :\n",
        "    - une image originale\n",
        "    - son image reconstruite\n",
        "\n",
        "\n",
        "6. Tester différentes tailles de la couche latente (2, 8, 32…)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301ddace",
      "metadata": {
        "id": "301ddace"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=16):\n",
        "        super().__init__()\n",
        "\n",
        "        ## ---- ENCODEUR ----\n",
        "        self.encoder = nn.Sequential(\n",
        "            # TODO: ajouter la couche latente\n",
        "            ...\n",
        "        )\n",
        "\n",
        "        ## ---- DECODEUR ----\n",
        "        self.decoder = nn.Sequential(\n",
        "            # TODO: partir de couche latente\n",
        "            ...\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "\n",
        "model = Autoencoder(...)\n",
        "\n",
        "# Optimiseur & loss\n",
        "criterion = ...\n",
        "optimizer = ...\n",
        "\n",
        "# Boucle d'entraînement (train_loader déjà défini)\n",
        "for epoch in range(...):\n",
        "    model.train()\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c51165",
      "metadata": {
        "id": "b6c51165"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5600e2f3",
      "metadata": {
        "id": "5600e2f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de3fc3f",
      "metadata": {
        "id": "3de3fc3f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}